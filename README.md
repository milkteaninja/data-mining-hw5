# stat-6240-hw5
Use the caret package to tune the parameters of a one-hidden-layer neural network.
You can find instructions for caret at http://topepo.github.io/caret/index.html. Also, see the caret_example.R file for an example. You will perform 10 fold cross-validation on the dataset and compare the “mse” of each model to find the ideal parameters for number of nodes in the hidden layer (size), the dropout rate (dropout), the training batch size (batch_size), the learning rate (lr) and the activation function (activation, possible choices are relu, sigmoid and tanh). Instead of comparing all possible choices at once, you should fix some of the parameter values and optimize over the others. That is, instead of supplying a tuneGrid with all possible values of the parameters, use a grid in which only two variables’ values change, and fix other values to a reasonable number.
